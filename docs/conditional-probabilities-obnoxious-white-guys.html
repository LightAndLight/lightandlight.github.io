<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="preload" href="/fonts/SourceSerif4/SourceSerif4-Regular.woff2" as="font" type="font/woff2" crossorigin>
  <link rel="preload" href="/fonts/SourceSans3/SourceSans3-Regular.woff2" as="font" type="font/woff2" crossorigin>

  <link rel="stylesheet" href="/res/fonts.css">
  <link rel="stylesheet" href="/res/style.css">

  <!-- defer non-critical stylesheet -->
  <link href="/res/syntax.css" rel="preload" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <noscript><link rel="stylesheet" href="/res/syntax.css"></noscript>

  
  <link rel="stylesheet" href="/res/math.css">
  

  

  

  
  <title>Conditional Probabilities and Obnoxious White Guys - blog.ielliott.io</title>
  

  <link rel="canonical" href="https://blog.ielliott.io/conditional-probabilities-obnoxious-white-guys">
<link rel="alternate" type="application/atom+xml" title="blog.ielliott.io" href="/feed.xml">

<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="blog.ielliott.io">
<meta property="og:url" content="https://blog.ielliott.io/conditional-probabilities-obnoxious-white-guys">
<meta property="og:title" content="Conditional Probabilities and Obnoxious White Guys">
<meta name="twitter:card" content="summary">
<meta property="twitter:title" content="Conditional Probabilities and Obnoxious White Guys">


<meta name="author" content="Isaac Elliott">
<meta name="description" content="In this Twitter thread,
Eugenia Cheng talks about how she presented at a conference for women in STEM, and was
confronted by a white guy who felt 'called out' by some of her anecdotes. Apparently, she
described interactions with obnoxious individuals in a professional setting, and noted that
they were all white guys. Ironically, the guy raised the issue in such a way that he was added
to the list of anecdotes.">
<meta property="og:description" content="In this Twitter thread,
Eugenia Cheng talks about how she presented at a conference for women in STEM, and was
confronted by a white guy who felt 'called out' by some of her anecdotes. Apparently, she
described interactions with obnoxious individuals in a professional setting, and noted that
they were all white guys. Ironically, the guy raised the issue in such a way that he was added
to the list of anecdotes.">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2019-05-05T00:00+00:00">

<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline":"Conditional Probabilities and Obnoxious White Guys",
  "author": {
    "@type":"Person",
    "name":"Isaac Elliott"
  },
  "datePublished":"2019-05-05T00:00+00:00",
  "dateModified":"2019-05-05T00:00+00:00",
  "description":"In this Twitter thread,
Eugenia Cheng talks about how she presented at a conference for women in STEM, and was
confronted by a white guy who felt 'called out' by some of her anecdotes. Apparently, she
described interactions with obnoxious individuals in a professional setting, and noted that
they were all white guys. Ironically, the guy raised the issue in such a way that he was added
to the list of anecdotes.",
  "mainEntityOfPage": {
    "@type":"WebPage",
    "@id":"https://blog.ielliott.io/conditional-probabilities-obnoxious-white-guys"
  },
  "url": "https://blog.ielliott.io/conditional-probabilities-obnoxious-white-guys"
}
</script>
</head>

<body>
  <header>
    <h1><a href="/">I E</a></h1>
    <nav>
      <ol>
        <li><a href="/">Home</a>
        <li><a href="/about">About</a>
        <li><a href="/resources">Resources</a>
      </ol>
    </nav>
  </header>

  <main>
    
    <script id="mathml-polyfill-script" src="/res/mathml-polyfill.js"></script>
    

    <article>
  <header>
    <h1>Conditional Probabilities and Obnoxious White Guys</h1>
    <p class="post-metadata">
       5 May, 2019
      
      ⋅
      
<a class="post-metadata-tag" href="/tags/rationality">rationality</a>

<a class="post-metadata-tag" href="/tags/mathematics">mathematics</a>


      
    </p>
  </header>
  <p>In <a href="https://twitter.com/DrEugeniaCheng/status/1124795257814691841">this Twitter thread</a>,
Eugenia Cheng talks about how she presented at a conference for women in STEM, and was
confronted by a white guy who felt ‘called out’ by some of her anecdotes. Apparently, she
described interactions with obnoxious individuals in a professional setting, and noted that
they were all white guys. Ironically, the guy raised the issue in such a way that he was added
to the list of anecdotes.</p>
<p>Later, Dr. Cheng <a href="https://twitter.com/DrEugeniaCheng/status/1124805201452515328">clearly states her position</a>.</p>
<blockquote>
<p>…people being obnoxious to me professionally are almost all white guys…</p>
</blockquote>
<p>Many people take her word for it, but some (particularly white guys) are skeptical. I’m going to
quickly examine some degrees of belief in her claim through the lens of probability theory.</p>
<hr />
<p>To begin, I want to explain why I have bothered to think about this. I believe Eugenia’s statement;
I have no reason to think that she’s mistaken or lying. But in spite of this, for some reason, I
empathised with the aforementioned white guy. Why? My unease wasn’t caused by any conscious
reasoning process; it just seemed to arise of its own accord.</p>
<p>I’ve been learning that <a href="https://medium.com/@ThingMaker/focusing-for-skeptics-6b949ef33a4f">“focusing”</a>
can be a helpful way to unpack these confusing feelings. I didn’t go all-out focusing on this,
but throughout my inquiry I made sure to be conscious of how my reasoning interacted with the feeling.</p>
<p>To paint a better picture of the feeling, it was something like:</p>
<ul>
<li>“Tenseness”</li>
<li>“Singled out”</li>
<li>“I feel like I’m about to fight something”</li>
</ul>
<p>To re-iterate: I don’t think these feelings were rational, which is why I decided to keep digging. Let’s
get into it. I’m going to assume basic familiarity with probability theory, and an understanding that
<a href="https://www.lesswrong.com/posts/f6ZLxEWaankRZ2Crv/probability-is-in-the-mind">probability is in the mind</a>.</p>
<p>I think Eugenia’s claim is this:
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mtext mathvariant="normal">person was white guy</mtext><mspace width="0.278em"></mspace><mo stretchy="false" form="prefix">|</mo><mspace width="0.278em"></mspace><mtext mathvariant="normal">interacted with obnoxious person</mtext><mo stretchy="true" form="postfix">)</mo></mrow><mo>&gt;</mo><mn>0.5</mn></mrow><annotation encoding="application/x-tex">P( \text{person was white guy} \; | \; \text{interacted with obnoxious person} ) &gt; 0.5</annotation></semantics></math>. In other
words: of all the obnoxious researchers she’s interacted with, most are white guys. Let’s look at the
conditional probability in terms of Bayes’ Theorem:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>W</mi><mi>G</mi><mo stretchy="false" form="prefix">|</mo><mi>O</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mfrac><mrow><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>O</mi><mo stretchy="false" form="prefix">|</mo><mi>W</mi><mi>G</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>⋅</mo><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>W</mi><mi>G</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mrow><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>O</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac></mrow><annotation encoding="application/x-tex"> P(WG | O) = \frac{P(O | WG) \cdot P(WG)}{P(O)} </annotation></semantics></math></p>
<p>To start with, I’ll plug in my estimates to show why I don’t disagree with her.</p>
<p>I think mathematics is pretty
male-dominated, so I’m going to say <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>W</mi><mi>G</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mn>0.7</mn></mrow><annotation encoding="application/x-tex">P(WG) = 0.7</annotation></semantics></math>. Seven in ten researchers she meets are white dudes.</p>
<p>Let’s then say that <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>O</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mn>0.1</mn></mrow><annotation encoding="application/x-tex">P(O) = 0.1</annotation></semantics></math> — one in ten researchers she interacts with are jerks (am I optimistic or
pessimistic about the academic community?).</p>
<p>Lastly there’s <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>O</mi><mo stretchy="false" form="prefix">|</mo><mi>W</mi><mi>G</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">P(O | WG)</annotation></semantics></math>: of all the white male researchers she meets, how many act
obnoxiously? I’m going to be charitable here and say (for demonstration purposes) that the white guys are
no more jerkish on average, so one in ten white male researchers she interacts with are jerks to her.
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>O</mi><mo stretchy="false" form="prefix">|</mo><mi>W</mi><mi>G</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mn>0.1</mn></mrow><annotation encoding="application/x-tex">P(O | WG) = 0.1</annotation></semantics></math>.</p>
<p>Now, compute!</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable><mtr><mtd columnalign="right" style="text-align: right"><mspace width="0.222em"></mspace></mtd><mtd columnalign="left" style="text-align: left"><mfrac><mrow><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>O</mi><mo stretchy="false" form="prefix">|</mo><mi>W</mi><mi>G</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>⋅</mo><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>W</mi><mi>G</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mrow><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>O</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac></mtd></mtr><mtr><mtd columnalign="right" style="text-align: right"></mtd></mtr><mtr><mtd columnalign="right" style="text-align: right"><mo>=</mo></mtd><mtd columnalign="left" style="text-align: left"><mspace width="0.278em"></mspace><mfrac><mrow><mn>0.1</mn><mo>⋅</mo><mn>0.7</mn></mrow><mn>0.1</mn></mfrac></mtd></mtr><mtr><mtd columnalign="right" style="text-align: right"></mtd></mtr><mtr><mtd columnalign="right" style="text-align: right"><mo>=</mo></mtd><mtd columnalign="left" style="text-align: left"><mspace width="0.278em"></mspace><mn>0.7</mn></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
~ &amp; \frac{P(O | WG) \cdot P(WG)}{P(O)} \\\\
= &amp; \; \frac{0.1 \cdot 0.7}{0.1} \\\\
= &amp; \; 0.7
\end{aligned}
</annotation></semantics></math></p>
<p>My estimate is consistent with her statement - of all the obnoxious researchers she meets, seven in ten
would be white guys, even when assuming zero racial/gender biases.</p>
<p>Suppose you disagree with me. That is, your estimates are such that <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>W</mi><mi>G</mi><mo stretchy="false" form="prefix">|</mo><mi>O</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>≤</mo><mn>0.5</mn></mrow><annotation encoding="application/x-tex">P(WG | O) \le 0.5</annotation></semantics></math>. There are two ways
to disagree here:</p>
<ol type="1">
<li><p>A lower ratio <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mfrac><mrow><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>O</mi><mo stretchy="false" form="prefix">|</mo><mi>W</mi><mi>G</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mrow><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>O</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac><annotation encoding="application/x-tex">\frac{P(O | WG)}{P(O)}</annotation></semantics></math>. You might take
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>O</mi><mo stretchy="false" form="prefix">|</mo><mi>W</mi><mi>G</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mn>0.07</mn></mrow><annotation encoding="application/x-tex">P(O | WG) = 0.07</annotation></semantics></math>, which means <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>W</mi><mi>G</mi><mo stretchy="false" form="prefix">|</mo><mi>O</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mn>0.49</mn></mrow><annotation encoding="application/x-tex">P(WG | O) = 0.49</annotation></semantics></math>. You might instead take
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>O</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mn>0.14</mn></mrow><annotation encoding="application/x-tex">P(O) = 0.14</annotation></semantics></math> for a similar result. Either way, you’re claiming that the fragment of
white male researchers Dr. Cheng meets are nicer on average than the general population of
researchers she has met.</p></li>
<li><p>A lower <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>W</mi><mi>G</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">P(WG)</annotation></semantics></math>, indicating that you think Dr. Cheng interacts with relatively fewer white
male researchers.</p></li>
</ol>
<p>Running through these calculations didn’t give me any closure. I agree on paper, and feel that my estimates are
appropriate. In fact, I would take <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mfrac><mrow><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>O</mi><mo stretchy="false" form="prefix">|</mo><mi>W</mi><mi>G</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mrow><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>O</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac><annotation encoding="application/x-tex">\frac{P(O | WG)}{P(O)}</annotation></semantics></math> to be slightly greater than one, to account
for biases like sexism and racism. But that only means I agree more.</p>
<p>The idea that ‘clicked’ with me, that immediately resolved my inner turmoil, was this: somehow I’m implicitly
turning
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>W</mi><mi>G</mi><mo stretchy="false" form="prefix">|</mo><mi>O</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">P(WG | O)</annotation></semantics></math> into <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>O</mi><mo stretchy="false" form="prefix">|</mo><mi>W</mi><mi>G</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">P(O | WG)</annotation></semantics></math>. <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>O</mi><mo stretchy="false" form="prefix">|</mo><mi>W</mi><mi>G</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">P(O | WG)</annotation></semantics></math> is the term from which stereotypes are born. If most
of the white guys you meet are jerks, then your <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>O</mi><mo stretchy="false" form="prefix">|</mo><mi>W</mi><mi>G</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">P(O | WG)</annotation></semantics></math> is high. If you don’t quotient that by the
proportion of people who are rude to you in general, then you have a gratuitous stereotype. If you do then
you’re completely justified in thinking that ‘white guy’ and ‘obnoxious’ are correlated. So I think that somehow
my wires were crossed and I was subconsciously interpreting the conversation as purely a statement about
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>O</mi><mo stretchy="false" form="prefix">|</mo><mi>W</mi><mi>G</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">P(O | WG)</annotation></semantics></math>.</p>
<p>I think this kind of error falls in the category of
<a href="https://en.wikipedia.org/wiki/Attribute_substitution">attribute substitution</a>, and I think it’s pretty common.
For example in <a href="https://www.youtube.com/watch?v=BrK7X_XlGB8">Julia Galef’s video about Bayes’ Theorem</a>, she says that before
students learn Bayes’ Theorem, they often give <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>B</mi><mo stretchy="false" form="prefix">|</mo><mi>A</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">P(B | A)</annotation></semantics></math> when asked for <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>A</mi><mo stretchy="false" form="prefix">|</mo><mi>B</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">P(A | B)</annotation></semantics></math>. I
don’t know how exactly this sort of thing happens — maybe I’ll explore that some other time.</p>
<p>Anyway, I’m glad that my feelings and beliefs are now in sync on this issue.</p>
  <p class="post-navigation">
    
    <a href="/learning-a-craft" title="Previous post: Learning a Craft">← Learning a Craft</a>
    

    
    <a href="/agda-nixos" title="Next post: Configuring Agda's standard library on NixOS">Configuring Agda's standard library on NixOS →</a>
    
  </p>
</article>

<div id="disqus_thread"></div>
<script type="text/javascript">
  /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
  var disqus_shortname = 'ielliott'; // required: replace example with your forum shortname

  /* * * DON'T EDIT BELOW THIS LINE * * */
  (function () {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>
<noscript>
  Please enable JavaScript to view the
  <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
</noscript>
  </main>

  <footer>
    <span>Isaac Elliott</span>

    <ol>
      <li><a class="footer-item-link" href="https://github.com/lightandlight">
        <svg class="footer-item-link-icon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 256"><path d="M208.31 75.68A59.78 59.78 0 0 0 202.93 28a8 8 0 0 0-6.93-4 59.75 59.75 0 0 0-48 24h-24a59.75 59.75 0 0 0-48-24 8 8 0 0 0-6.93 4 59.78 59.78 0 0 0-5.38 47.68A58.14 58.14 0 0 0 56 104v8a56.06 56.06 0 0 0 48.44 55.47A39.8 39.8 0 0 0 96 192v8H72a24 24 0 0 1-24-24 40 40 0 0 0-40-40 8 8 0 0 0 0 16 24 24 0 0 1 24 24 40 40 0 0 0 40 40h24v16a8 8 0 0 0 16 0v-40a24 24 0 0 1 48 0v40a8 8 0 0 0 16 0v-40a39.8 39.8 0 0 0-8.44-24.53A56.06 56.06 0 0 0 216 112v-8a58.14 58.14 0 0 0-7.69-28.32M200 112a40 40 0 0 1-40 40h-48a40 40 0 0 1-40-40v-8a41.74 41.74 0 0 1 6.9-22.48 8 8 0 0 0 1.1-7.69 43.8 43.8 0 0 1 .79-33.58 43.88 43.88 0 0 1 32.32 20.06 8 8 0 0 0 6.71 3.69h32.35a8 8 0 0 0 6.74-3.69 43.87 43.87 0 0 1 32.32-20.06 43.8 43.8 0 0 1 .77 33.58 8.09 8.09 0 0 0 1 7.65 41.7 41.7 0 0 1 7 22.52Z"></path></svg>
        GitHub
      </a>

      <li><a class="footer-item-link" href="mailto:blog@id.ielliott.io">
        <svg class="footer-item-link-icon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 256"><path d="M224 48H32a8 8 0 0 0-8 8v136a16 16 0 0 0 16 16h176a16 16 0 0 0 16-16V56a8 8 0 0 0-8-8m-20.57 16L128 133.15 52.57 64ZM216 192H40V74.19l82.59 75.71a8 8 0 0 0 10.82 0L216 74.19z"></path></svg>
        Email
      </a>

      <li><a class="footer-item-link" href="https://blog.ielliott.io/feed.xml">
        <svg class="footer-item-link-icon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 256"><path d="M224 192a8 8 0 0 1-16 0c0-79.4-64.6-144-144-144a8 8 0 0 1 0-16c88.22 0 160 71.78 160 160M64 104a8 8 0 0 0 0 16 72.08 72.08 0 0 1 72 72 8 8 0 0 0 16 0 88.1 88.1 0 0 0-88-88m4 72a12 12 0 1 0 12 12 12 12 0 0 0-12-12"></path></svg>
        Feed
      </a>
    </ol>
  </footer>

  
</body>

</html>